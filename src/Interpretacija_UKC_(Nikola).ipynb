{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "V28"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "TPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07edd032a5b140318fa2c7988e9cf149": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b5614d27fba4332a98085eee7e75062",
       "IPY_MODEL_353dc6e8a1de4506b0f986c7223dc7d9",
       "IPY_MODEL_d7dcaf6f940342828e2e1d35aa4dc97d"
      ],
      "layout": "IPY_MODEL_5b285cbe1d264025b6f0d7d337cd354f"
     }
    },
    "4b5614d27fba4332a98085eee7e75062": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_483377dd60a84e72bc71c7a4d8a047cb",
      "placeholder": "​",
      "style": "IPY_MODEL_971e04b0231d4bbe967ab0af3992c31a",
      "value": "model.safetensors: 100%"
     }
    },
    "353dc6e8a1de4506b0f986c7223dc7d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec04f0fc822d4fe485023228270fbae9",
      "max": 1112201288,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a49fd89d904048c78c1e200cfd18af01",
      "value": 1112201288
     }
    },
    "d7dcaf6f940342828e2e1d35aa4dc97d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d79a3f22b3748fca36c6708a0897d08",
      "placeholder": "​",
      "style": "IPY_MODEL_5516f359815b47a1ba0aab1985a996ea",
      "value": " 1.11G/1.11G [00:00&lt;00:00, 82.0MB/s]"
     }
    },
    "5b285cbe1d264025b6f0d7d337cd354f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "483377dd60a84e72bc71c7a4d8a047cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "971e04b0231d4bbe967ab0af3992c31a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec04f0fc822d4fe485023228270fbae9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a49fd89d904048c78c1e200cfd18af01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4d79a3f22b3748fca36c6708a0897d08": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5516f359815b47a1ba0aab1985a996ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlNqDM31OCxO",
    "outputId": "395a0dde-a495-411e-8b18-07dcabd12757",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:43.787139Z",
     "start_time": "2024-06-13T05:59:41.275169Z"
    }
   },
   "source": [
    "!pip install pandas\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from pandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "source": [
    "import openpyxl"
   ],
   "metadata": {
    "id": "lxTYL-OpOhCJ",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:43.801475Z",
     "start_time": "2024-06-13T05:59:43.793018Z"
    }
   },
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(os.path.join('..', 'data', 'Reworkan data 4.xlsx'))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "G2KFi1tFOiFX",
    "outputId": "2c3010f7-6dae-45a0-ed9e-0b80dcb5b76b",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:46.941648Z",
     "start_time": "2024-06-13T05:59:43.804912Z"
    }
   },
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "source": [
    "print(type(data))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bHk6z5JLOlhk",
    "outputId": "bb7479ab-2811-4a48-fe02-82d8f856f19b",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:46.950678Z",
     "start_time": "2024-06-13T05:59:46.944732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "source": [
    "# Print each column name to check for extra spaces or non-visible characters\n",
    "for col in data.columns:\n",
    "    print(f\"'{col}'\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3FDjwfdQOmqU",
    "outputId": "134473e1-106e-48c5-8dd0-9620ab1245e7",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:46.981968Z",
     "start_time": "2024-06-13T05:59:46.953352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Article ID'\n",
      "'Datum'\n",
      "'Dan'\n",
      "'Teden'\n",
      "'Article created'\n",
      "'Tip medija'\n",
      "'Podtip medija'\n",
      "'Media uuid'\n",
      "'Medij'\n",
      "'Rubric uuid'\n",
      "'Rubrika'\n",
      "'Publisher uuid'\n",
      "'Medijski založnik'\n",
      "'Doseg medijskega založnika'\n",
      "'Media circulation'\n",
      "'Lokalnost'\n",
      "'Periodika'\n",
      "'Medijske teme'\n",
      "'Naslov objave'\n",
      "'Država medija'\n",
      "'Mesto'\n",
      "'Država'\n",
      "'Opis'\n",
      "'Page/dur'\n",
      "'Število strani'\n",
      "'Avtor'\n",
      "'Entity uuid'\n",
      "'Analizirana entiteta'\n",
      "'Class uuid'\n",
      "'Krovne teme'\n",
      "'Object uuid'\n",
      "'Teme'\n",
      "'Obj rate'\n",
      "'Obj size'\n",
      "'Obj cash'\n",
      "'Obj description'\n",
      "'Quoted source'\n",
      "'Quoted src rate'\n",
      "'Ouoted src description'\n",
      "'Reporting tone rate'\n",
      "'Picture rate'\n",
      "'Company mention title rate'\n",
      "'Company mention subtitle rate'\n",
      "'Representatives quotes rate'\n",
      "'Quoted sources - third party'\n",
      "'Planned publicity rate'\n",
      "'Primary publicity rate'\n",
      "'Size'\n",
      "'Size rate'\n",
      "'Key messages rate'\n",
      "'Article reach value'\n",
      "'Article position value'\n",
      "'Final rate'\n",
      "'Cash'\n",
      "'Whole article value'\n",
      "'Reach'\n",
      "'Important'\n",
      "'Načrtovanost'\n",
      "'Primarnost objave'\n",
      "'Naklonjenost tematike'\n",
      "'Prisotnost ključnih sporočil'\n",
      "'Ocena velikosti pojavljanja naročnika'\n",
      "'Prisotnost fotografije'\n",
      "'Citat tretje osebe'\n",
      "'Citat predstavnika podjetja'\n",
      "'Omemba podjetja v naslovu'\n",
      "'Omemba podjetja v podnaslovu'\n",
      "'Article url'\n",
      "'Prisotnost citiranih virov'\n",
      "'Prisotnost predstavnika podjetja'\n",
      "'Pregled objav - citiranost virov'\n",
      "'Razredi Indeksa medijske podobe'\n",
      "'Doseg'\n",
      "'Naklonjenost teme'\n",
      "'Osrednja tema'\n",
      "'Ključna sporočila'\n",
      "'Fotografija'\n",
      "'Omemba v naslovu'\n",
      "'Omemba v podnaslovu'\n",
      "'Tekst'\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "source": [
    "# Assume data is already loaded into a DataFrame\n",
    "\n",
    "\n",
    "# Convert 'Datum' column to string if not already\n",
    "data['Datum'] = data['Datum'].astype(str)\n",
    "\n",
    "\n",
    "# Extract the first 10 characters from each entry in 'Datum' to get the date in 'YYYY-MM-DD' format\n",
    "data['Datum'] = data['Datum'].str.slice(0, 10)\n",
    "\n",
    "# Convert the extracted string back to datetime to ensure it is in standard date format\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "# Now 'Datum' contains datetime objects in a standardized format\n",
    "print(data['Datum'].head())\n",
    "\n",
    "# Convert datetime to date string for display purposes\n",
    "data['Datum'] = data['Datum'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# Check the data type of 'Datum'\n",
    "print(data['Datum'].dtype)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sToxPl9QcAKI",
    "outputId": "9b5e3dd3-cbf5-4b5c-d949-9a0b060d13b1",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:47.034738Z",
     "start_time": "2024-06-13T05:59:46.984193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2023-04-06\n",
      "1   2023-04-07\n",
      "2   2023-04-15\n",
      "3   2023-04-04\n",
      "4   2023-04-17\n",
      "Name: Datum, dtype: datetime64[ns]\n",
      "object\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the date strings back to datetime objects\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "# Extract the month name\n",
    "data['Month_Name'] = data['Datum'].dt.month_name()\n",
    "\n",
    "# Get the month name and year of the last row\n",
    "zadnji_mesec = data['Month_Name'].iloc[-1]\n",
    "leto = data['Datum'].dt.year.iloc[-1]\n",
    "\n",
    "# Create a combined variable of the last month and year\n",
    "zadnji_mesec_leto = f\"{zadnji_mesec} {leto}\"\n",
    "\n",
    "# Calculate date one year before the last date\n",
    "datum_pred_enim_letom = data['Datum'].iloc[-1] - pd.DateOffset(years=1)\n",
    "\n",
    "# Extract month and year from this date\n",
    "mesec_pred_enim_letom = datum_pred_enim_letom.month_name()\n",
    "leto_pred_enim_letom = datum_pred_enim_letom.year\n",
    "\n",
    "# Combine them into one string\n",
    "mesec_leto_pred_enim_letom = f\"{mesec_pred_enim_letom} {leto_pred_enim_letom}\"\n",
    "\n",
    "# Convert datetime to date string for display purposes\n",
    "data['Datum'] = data['Datum'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "print(zadnji_mesec_leto)\n",
    "print(mesec_leto_pred_enim_letom)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6gijUVfcEcd",
    "outputId": "032f9f4b-834c-4e6e-c8ce-1d43aebd3391",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:47.056474Z",
     "start_time": "2024-06-13T05:59:47.037066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April 2024\n",
      "April 2023\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "source": [
    "entiteta = data['Analizirana entiteta'][0]\n",
    "\n",
    "print(entiteta)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fv4BG7NQoBBS",
    "outputId": "fa249461-5bb2-495c-b045-9785df74432c",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:47.063439Z",
     "start_time": "2024-06-13T05:59:47.058036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKC Ljubljana\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# I'm assuming your data variable is a DataFrame that you have already prepared\n",
    "# Here's the continuation of your script:\n",
    "\n",
    "# Convert the date strings back to datetime objects\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "# Extract the month name and year for easy filtering\n",
    "data['Month_Name'] = data['Datum'].dt.month_name()\n",
    "data['Year'] = data['Datum'].dt.year\n",
    "\n",
    "# Get the month name and year of the last row\n",
    "zadnji_mesec = data['Month_Name'].iloc[-1]\n",
    "leto = data['Year'].iloc[-1]\n",
    "zadnji_mesec_leto = f\"{zadnji_mesec} {leto}\"\n",
    "\n",
    "# Calculate date one year before the last date\n",
    "datum_pred_enim_letom = data['Datum'].iloc[-1] - pd.DateOffset(years=1)\n",
    "mesec_pred_enim_letom = datum_pred_enim_letom.month_name()\n",
    "leto_pred_enim_letom = datum_pred_enim_letom.year\n",
    "mesec_leto_pred_enim_letom = f\"{mesec_pred_enim_letom} {leto_pred_enim_letom}\"\n",
    "\n",
    "# Filter data for zadnji mesec leto\n",
    "filtered_data_zadnji = data[(data['Month_Name'] == zadnji_mesec) & (data['Year'] == leto)]\n",
    "unique_uuids_zadnji = filtered_data_zadnji['Article ID'].nunique()\n",
    "\n",
    "# Filter data for mesec leto pred enim letom\n",
    "filtered_data_pred = data[(data['Month_Name'] == mesec_pred_enim_letom) & (data['Year'] == leto_pred_enim_letom)]\n",
    "unique_uuids_pred = filtered_data_pred['Article ID'].nunique()\n",
    "\n",
    "# Output the results\n",
    "print(f\"Total Unique UUIDs for {zadnji_mesec_leto}: {unique_uuids_zadnji}\")\n",
    "print(f\"Total Unique UUIDs for {mesec_leto_pred_enim_letom}: {unique_uuids_pred}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_fGP4UqoSUa",
    "outputId": "36ff95ae-fd06-495f-d473-73cb3d1ad8eb",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:47.095082Z",
     "start_time": "2024-06-13T05:59:47.065050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique UUIDs for April 2024: 303\n",
      "Total Unique UUIDs for April 2023: 455\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate percentage difference between unique UUID counts\n",
    "if unique_uuids_pred == 0:\n",
    "    percentage_difference = \"Undefined\"  # Avoid division by zero\n",
    "else:\n",
    "    percentage_difference = ((unique_uuids_zadnji - unique_uuids_pred) / unique_uuids_pred) * 100\n",
    "    percentage_difference = f\"{percentage_difference:.1f}\"  # Format to one decimal place\n",
    "\n",
    "# Print the percentage difference\n",
    "print(f\"Percentage difference in unique UUIDs: {percentage_difference}%\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5XpzIN9I3aI",
    "outputId": "2d65215e-0451-430f-8cf6-53d1deecc5b9",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:47.106381Z",
     "start_time": "2024-06-13T05:59:47.100176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage difference in unique UUIDs: -33.4%\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# I'm assuming your data variable is a DataFrame that you have already prepared\n",
    "# Here's the continuation of your script:\n",
    "\n",
    "# Convert the date strings back to datetime objects\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "# Extract the month name and year for easy filtering\n",
    "data['Month_Name'] = data['Datum'].dt.month_name()\n",
    "data['Year'] = data['Datum'].dt.year\n",
    "\n",
    "# Get the month name and year of the last row\n",
    "zadnji_mesec = data['Month_Name'].iloc[-1]\n",
    "leto = data['Year'].iloc[-1]\n",
    "\n",
    "# Calculate date one year before the last date\n",
    "datum_pred_enim_letom = data['Datum'].iloc[-1] - pd.DateOffset(years=1)\n",
    "mesec_pred_enim_letom = datum_pred_enim_letom.month_name()\n",
    "leto_pred_enim_letom = datum_pred_enim_letom.year\n",
    "\n",
    "# Filter data for the last month and year\n",
    "filtered_data_zadnji = data[(data['Month_Name'] == zadnji_mesec) & (data['Year'] == leto)]\n",
    "filtered_data_pred = data[(data['Month_Name'] == mesec_pred_enim_letom) & (data['Year'] == leto_pred_enim_letom)]\n",
    "\n",
    "# Remove duplicates based on 'Article ID' before summing\n",
    "filtered_data_zadnji_unique = filtered_data_zadnji.drop_duplicates(subset='Article ID')\n",
    "filtered_data_pred_unique = filtered_data_pred.drop_duplicates(subset='Article ID')\n",
    "\n",
    "# Group by 'Tip medija' and sum 'Whole article value' for last month year\n",
    "grouped_by_tip_medija_sum_zadnji = filtered_data_zadnji_unique.groupby('Tip medija')['Whole article value'].sum()\n",
    "total_vrednost_sum_zadnji = int(grouped_by_tip_medija_sum_zadnji.sum())\n",
    "\n",
    "# Group by 'Tip medija' and sum 'Whole article value' for one year before\n",
    "grouped_by_tip_medija_sum_pred = filtered_data_pred_unique.groupby('Tip medija')['Whole article value'].sum()\n",
    "total_vrednost_sum_pred = int(grouped_by_tip_medija_sum_pred.sum())\n",
    "\n",
    "# Calculate percentage difference between these sums\n",
    "if total_vrednost_sum_pred == 0:\n",
    "    percentage_difference_value = \"Undefined\"  # Avoid division by zero\n",
    "else:\n",
    "    percentage_difference_value = ((total_vrednost_sum_zadnji - total_vrednost_sum_pred) / total_vrednost_sum_pred) * 100\n",
    "    percentage_difference_value = f\"{percentage_difference_value:.1f}\"  # Format to one decimal place\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total value sum for last month year: {total_vrednost_sum_zadnji}\")\n",
    "print(f\"Total value sum for one year before: {total_vrednost_sum_pred}\")\n",
    "print(f\"Percentage difference in total value: {percentage_difference_value}%\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7xy7qmppeRQ",
    "outputId": "c0aeeda7-311b-4f9e-c040-f03289843f30",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:47.144044Z",
     "start_time": "2024-06-13T05:59:47.107962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total value sum for last month year: 966289\n",
      "Total value sum for one year before: 1643640\n",
      "Percentage difference in total value: -41.2%\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# I'm assuming your data variable is a DataFrame that you have already prepared\n",
    "# Here's the continuation of your script:\n",
    "\n",
    "# Convert the date strings back to datetime objects\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "# Extract the month name and year for easy filtering\n",
    "data['Month_Name'] = data['Datum'].dt.month_name()\n",
    "data['Year'] = data['Datum'].dt.year\n",
    "\n",
    "# Get the month name and year of the last row\n",
    "zadnji_mesec = data['Month_Name'].iloc[-1]\n",
    "leto = data['Year'].iloc[-1]\n",
    "\n",
    "# Filter data for the last month and year\n",
    "filtered_data_zadnji = data[(data['Month_Name'] == zadnji_mesec) & (data['Year'] == leto)]\n",
    "\n",
    "# Calculate the total unique 'Article ID' for the last month and year\n",
    "total_unique_uuids_last_month = filtered_data_zadnji['Article ID'].nunique()\n",
    "\n",
    "# Calculate unique 'Article ID' counts for each category in the last month and year\n",
    "unique_uuid_count_nenaklonjeno = filtered_data_zadnji[filtered_data_zadnji['Naklonjenost tematike'] == 'Nenaklonjeno']['Article ID'].nunique()\n",
    "unique_uuid_count_naklonjeno = filtered_data_zadnji[filtered_data_zadnji['Naklonjenost tematike'] == 'Naklonjeno']['Article ID'].nunique()\n",
    "unique_uuid_count_nevtralno = filtered_data_zadnji[filtered_data_zadnji['Naklonjenost tematike'] == 'Nevtralno']['Article ID'].nunique()\n",
    "\n",
    "# Calculate percentages\n",
    "percentage_nenaklonjeno_objave = (unique_uuid_count_nenaklonjeno / total_unique_uuids_last_month) * 100\n",
    "percentage_naklonjeno_objave = (unique_uuid_count_naklonjeno / total_unique_uuids_last_month) * 100\n",
    "percentage_nevtralno_objave = (unique_uuid_count_nevtralno / total_unique_uuids_last_month) * 100\n",
    "\n",
    "# Print out the results for the last month and year with one decimal place\n",
    "print(f\"Percentage of Unique UUIDs for Nenaklonjeno in {zadnji_mesec} {leto}: {percentage_nenaklonjeno_objave:.1f}%\")\n",
    "print(f\"Percentage of Unique UUIDs for Naklonjeno in {zadnji_mesec} {leto}: {percentage_naklonjeno_objave:.1f}%\")\n",
    "print(f\"Percentage of Unique UUIDs for Nevtralno in {zadnji_mesec} {leto}: {percentage_nevtralno_objave:.1f}%\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNu7kBkypbo_",
    "outputId": "c8691878-03ab-4e59-fd49-6cc44bc39bcc",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:47.169387Z",
     "start_time": "2024-06-13T05:59:47.145469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Unique UUIDs for Nenaklonjeno in April 2024: 6.3%\n",
      "Percentage of Unique UUIDs for Naklonjeno in April 2024: 3.6%\n",
      "Percentage of Unique UUIDs for Nevtralno in April 2024: 90.1%\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# I'm assuming your data variable is a DataFrame that you have already prepared\n",
    "# Here's the continuation of your script:\n",
    "\n",
    "# Convert the date strings back to datetime objects\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "# Extract the month name and year for easy filtering\n",
    "data['Month_Name'] = data['Datum'].dt.month_name()\n",
    "data['Year'] = data['Datum'].dt.year\n",
    "\n",
    "# Get the month name and year of the last row\n",
    "zadnji_mesec = data['Month_Name'].iloc[-1]\n",
    "leto = data['Year'].iloc[-1]\n",
    "\n",
    "# Filter data for the last month and year\n",
    "filtered_data_zadnji = data[(data['Month_Name'] == zadnji_mesec) & (data['Year'] == leto)]\n",
    "\n",
    "# Remove duplicates based on 'Article ID' before grouping\n",
    "filtered_data_zadnji_unique = filtered_data_zadnji.drop_duplicates(subset='Article ID')\n",
    "\n",
    "# Group by 'Tip medija' and count unique 'Article ID'\n",
    "unique_article_by_tip_medija = filtered_data_zadnji_unique.groupby('Tip medija')['Article ID'].nunique()\n",
    "\n",
    "# Calculate the total number of unique 'Article ID' in the last month\n",
    "total_unique_articles_last_month = unique_article_by_tip_medija.sum()\n",
    "\n",
    "# Calculate percentage for each media type and create separate variables\n",
    "percentage_internet = f\"{(unique_article_by_tip_medija.get('internet', 0) / total_unique_articles_last_month * 100):.2f}%\"\n",
    "percentage_radio = f\"{(unique_article_by_tip_medija.get('radio', 0) / total_unique_articles_last_month * 100):.2f}%\"\n",
    "percentage_tisk = f\"{(unique_article_by_tip_medija.get('tisk', 0) / total_unique_articles_last_month * 100):.2f}%\"\n",
    "percentage_tv = f\"{(unique_article_by_tip_medija.get('tv', 0) / total_unique_articles_last_month * 100):.2f}%\"\n",
    "\n",
    "# Print the results\n",
    "print(f\"Percentage of Unique Article IDs for Internet: {percentage_internet}\")\n",
    "print(f\"Percentage of Unique Article IDs for Radio: {percentage_radio}\")\n",
    "print(f\"Percentage of Unique Article IDs for Tisk: {percentage_tisk}\")\n",
    "print(f\"Percentage of Unique Article IDs for TV: {percentage_tv}\")\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMqdsxDZMDoc",
    "outputId": "0792108b-1a8f-4427-ae1c-3ef9d9bd2d17",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:47.196248Z",
     "start_time": "2024-06-13T05:59:47.171066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Unique Article IDs for Internet: 50.17%\n",
      "Percentage of Unique Article IDs for Radio: 4.95%\n",
      "Percentage of Unique Article IDs for Tisk: 30.69%\n",
      "Percentage of Unique Article IDs for TV: 14.19%\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your data variable is a DataFrame that you have already prepared\n",
    "# Convert the date strings back to datetime objects\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "# Extract the month name and year for easy filtering\n",
    "data['Month_Name'] = data['Datum'].dt.month_name()\n",
    "data['Year'] = data['Datum'].dt.year\n",
    "\n",
    "# Get the month name and year of the last row\n",
    "zadnji_mesec = data['Month_Name'].iloc[-1]\n",
    "leto = data['Year'].iloc[-1]\n",
    "\n",
    "# Filter data for the last month and year\n",
    "filtered_data_zadnji = data[(data['Month_Name'] == zadnji_mesec) & (data['Year'] == leto)]\n",
    "\n",
    "# Remove duplicates based on 'Article ID' before grouping\n",
    "filtered_data_zadnji_unique = filtered_data_zadnji.drop_duplicates(subset='Article ID')\n",
    "\n",
    "# Group by 'Lokalnost' and count unique 'Article ID'\n",
    "unique_article_by_lokalnost = filtered_data_zadnji_unique.groupby('Lokalnost')['Article ID'].nunique()\n",
    "\n",
    "# Store the results in a variable\n",
    "unique_article_by_lokalnost_str = ', '.join([f\"{lokalnost} ({count})\" for lokalnost, count in unique_article_by_lokalnost.items()])\n",
    "\n",
    "# Additional filtering for 'Lokalnost' being 'regionalen'\n",
    "filtered_regionalen = filtered_data_zadnji_unique[filtered_data_zadnji_unique['Lokalnost'] == 'regionalen']\n",
    "\n",
    "# Group by 'Medij' and count unique 'Article ID' for 'regionalen'\n",
    "unique_article_by_medij = filtered_regionalen.groupby('Medij')['Article ID'].nunique()\n",
    "\n",
    "# Store the results in a variable\n",
    "unique_article_by_medij_str = ', '.join([f\"{medij} ({count})\" for medij, count in unique_article_by_medij.items()])\n",
    "\n",
    "# Print the results for verification\n",
    "print(f\"Unique Article IDs by Lokalnost: {unique_article_by_lokalnost_str}\")\n",
    "print(f\"Article counts for 'regionalen' by Medij: {unique_article_by_medij_str}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qE9eYvLPX85",
    "outputId": "df080ce4-7cdd-46ff-8fe9-73687b9c1e5b",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:47.223254Z",
     "start_time": "2024-06-13T05:59:47.198107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Article IDs by Lokalnost: nacionalni (290), regionalen (13)\n",
      "Article counts for 'regionalen' by Medij: Primorske novice (6), Večer (6), Večer - V soboto (1)\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install openai\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKbzURP2AghI",
    "outputId": "80c13c8e-6c7d-4557-f152-e5435ac3ace1",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:49.686191Z",
     "start_time": "2024-06-13T05:59:47.224664Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (1.33.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (4.4.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (2.7.3)\r\n",
      "Requirement already satisfied: sniffio in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (4.12.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\r\n",
      "Requirement already satisfied: certifi in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# I'm assuming your data variable is a DataFrame that you have already prepared\n",
    "# Here's the continuation of your script:\n",
    "\n",
    "# Convert the date strings back to datetime objects\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "# Extract the month name and year for easy filtering\n",
    "data['Month_Name'] = data['Datum'].dt.month_name()\n",
    "data['Year'] = data['Datum'].dt.year\n",
    "\n",
    "# Get the month name and year of the last row\n",
    "zadnji_mesec = data['Month_Name'].iloc[-1]\n",
    "leto = data['Year'].iloc[-1]\n",
    "\n",
    "# Filter data for the last month and year\n",
    "filtered_data_zadnji = data[(data['Month_Name'] == zadnji_mesec) & (data['Year'] == leto)]\n",
    "\n",
    "# Remove duplicates based on 'Article ID' before grouping\n",
    "filtered_data_zadnji_unique = filtered_data_zadnji.drop_duplicates(subset='Article ID')\n",
    "\n",
    "# Assign week number to each date in the last month\n",
    "filtered_data_zadnji_unique['Week_Number'] = filtered_data_zadnji_unique['Datum'].dt.isocalendar().week\n",
    "\n",
    "# Group by week number and count unique 'Article ID'\n",
    "unique_article_by_week = filtered_data_zadnji_unique.groupby('Week_Number')['Article ID'].nunique()\n",
    "\n",
    "# Find the week with the maximum count of unique 'Article ID'\n",
    "max_articles_week = unique_article_by_week.idxmax()\n",
    "max_articles_count = unique_article_by_week[max_articles_week]\n",
    "\n",
    "# Calculate the min and max date for the week with maximum unique 'Article ID'\n",
    "week_dates = filtered_data_zadnji_unique[filtered_data_zadnji_unique['Week_Number'] == max_articles_week]['Datum']\n",
    "min_date = week_dates.min()\n",
    "max_date = week_dates.max()\n",
    "\n",
    "# Group by date within the max week and count unique 'Article ID'\n",
    "daily_counts = filtered_data_zadnji_unique[filtered_data_zadnji_unique['Week_Number'] == max_articles_week].groupby('Datum')['Article ID'].nunique()\n",
    "\n",
    "# Find the day with the maximum count of unique 'Article ID'\n",
    "max_articles_day = daily_counts.idxmax()\n",
    "max_articles_day_count = daily_counts[max_articles_day]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Week with maximum unique Article ID: Week {max_articles_week} with {max_articles_count} unique Article IDs\")\n",
    "print(f\"Minimum date in this week: {min_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Maximum date in this week: {max_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Day with the most Article IDs in this week: {max_articles_day.strftime('%Y-%m-%d')} with {max_articles_day_count} unique Article IDs\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spOvV54jAwir",
    "outputId": "e0b3ce78-b953-46a8-a8d5-0ec5d81da5a1",
    "ExecuteTime": {
     "end_time": "2024-06-13T05:59:50.558901Z",
     "start_time": "2024-06-13T05:59:49.691089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week with maximum unique Article ID: Week 17 with 138 unique Article IDs\n",
      "Minimum date in this week: 2024-04-22\n",
      "Maximum date in this week: 2024-04-28\n",
      "Day with the most Article IDs in this week: 2024-04-22 with 33 unique Article IDs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_647601/647513584.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data_zadnji_unique['Week_Number'] = filtered_data_zadnji_unique['Datum'].dt.isocalendar().week\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "source": [
    "OD TUKAJ DALJE RABIM COLUMN *Cluster"
   ],
   "metadata": {
    "id": "x_80FFAxXcSA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers numpy torch tiktoken openai\n",
    "\n",
    "import pandas as pd  # assuming knime needs import at every cell jupyter doesnt need this\n",
    "import openai\n",
    "import torch\n",
    "import tiktoken\n",
    "import torch.nn.functional as functional\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def _average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "\n",
    "def _e5_embed(text, tokenizer, model, max_len):\n",
    "    if isinstance(text, float):\n",
    "        print(text)\n",
    "        text = str(text)\n",
    "    batch_dict = tokenizer(\n",
    "        ['passage: ' + text], max_length=max_len,\n",
    "        padding=True, truncation=True, return_tensors='pt'\n",
    "    )\n",
    "    batch_dict.to(device)\n",
    "    outputs = model(**batch_dict)\n",
    "    embeddings = _average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "    embeddings = functional.normalize(embeddings, p=2, dim=1)\n",
    "    return embeddings.detach().cpu().numpy()[0]\n",
    "\n",
    "\n",
    "def e5embed(df: pd.DataFrame, col_name: str):\n",
    "    model_name = \"intfloat/multilingual-e5-base\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
    "    model.to(device)\n",
    "    print(\"Loaded model\")\n",
    "    df['Embedding'] = df[col_name].apply(_e5_embed, model=model, tokenizer=tokenizer, max_len=512)\n",
    "    print(\"Computed embeddings\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def _oai_embed(text, encoding):\n",
    "    tokens = encoding.encode(text)[:8191]\n",
    "    embedding = openai.embeddings.create(  # call OpenAI\n",
    "        input=tokens, model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return embedding.data[0].embedding\n",
    "\n",
    "def openai_embed(df: pd.DataFrame, col_name: str):\n",
    "    encoding = tiktoken.get_encoding('cl100k_base')\n",
    "    df['Embedding'] = df[col_name].apply(_oai_embed, encoding=encoding)\n",
    "    return data\n",
    "\n",
    "# Compute OpenAI embeddings\n",
    "# data = openai_embed(data, 'Tekst')\n",
    "\n",
    "# Compute Kliping free embeddings\n",
    "data = e5embed(data, 'Tekst')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 967,
     "referenced_widgets": [
      "07edd032a5b140318fa2c7988e9cf149",
      "4b5614d27fba4332a98085eee7e75062",
      "353dc6e8a1de4506b0f986c7223dc7d9",
      "d7dcaf6f940342828e2e1d35aa4dc97d",
      "5b285cbe1d264025b6f0d7d337cd354f",
      "483377dd60a84e72bc71c7a4d8a047cb",
      "971e04b0231d4bbe967ab0af3992c31a",
      "ec04f0fc822d4fe485023228270fbae9",
      "a49fd89d904048c78c1e200cfd18af01",
      "4d79a3f22b3748fca36c6708a0897d08",
      "5516f359815b47a1ba0aab1985a996ea"
     ]
    },
    "id": "j7XRnSn-gEsc",
    "outputId": "96bff0da-1c6a-4959-f56f-f6dbbdc94a44",
    "ExecuteTime": {
     "end_time": "2024-06-13T06:01:21.539125Z",
     "start_time": "2024-06-13T05:59:50.560297Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (4.34.0)\r\n",
      "Requirement already satisfied: numpy in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (1.26.4)\r\n",
      "Requirement already satisfied: torch in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: tiktoken in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (0.7.0)\r\n",
      "Requirement already satisfied: openai in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (1.33.0)\r\n",
      "Requirement already satisfied: filelock in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from transformers) (3.14.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from transformers) (0.17.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from transformers) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from transformers) (2024.5.15)\r\n",
      "Requirement already satisfied: requests in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from transformers) (0.14.1)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from transformers) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (1.12.1)\r\n",
      "Requirement already satisfied: networkx in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (2024.3.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (10.3.2.106)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (2.20.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (12.1.105)\r\n",
      "Requirement already satisfied: triton==2.3.1 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from torch) (2.3.1)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (4.4.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (2.7.3)\r\n",
      "Requirement already satisfied: sniffio in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (1.3.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\r\n",
      "Requirement already satisfied: certifi in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Loaded model\n",
      "nan\n",
      "nan\n",
      "Computed embeddings\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install networkx numpy scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Assuming your data variable is a DataFrame that you have already prepared\n",
    "# Continuing from the last step of the previous script\n",
    "\n",
    "def cluster_louvain(df: pd.DataFrame, similarity_threshold: float = 0.96):\n",
    "    print(\"Clustering ...\")\n",
    "    embeddings = np.array(df['Embedding'].to_list())\n",
    "    labels = [0] * len(embeddings)\n",
    "    x = cosine_similarity(embeddings, embeddings)\n",
    "    similarity_matrix = x > similarity_threshold\n",
    "    G = nx.from_numpy_array(similarity_matrix)\n",
    "    communities = nx.algorithms.community.louvain_communities(G, resolution=0.1)\n",
    "    for community in communities:\n",
    "        initial_member = min(community)\n",
    "        for member in community:\n",
    "            labels[member] = initial_member\n",
    "\n",
    "    df['Cluster'] = pd.Series(labels)\n",
    "    print(\"Clustered\")\n",
    "    return df\n",
    "\n",
    "# Compute clustering\n",
    "data = cluster_louvain(data, 0.92)  # <- similarity_threshold\n",
    "data.head(100)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "id": "85xWTBwYnaav",
    "outputId": "c69f6194-114f-425f-9292-d6077a2c51ab",
    "ExecuteTime": {
     "end_time": "2024-06-13T06:01:26.030068Z",
     "start_time": "2024-06-13T06:01:21.548228Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (3.3)\r\n",
      "Requirement already satisfied: numpy in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (1.26.4)\r\n",
      "Requirement already satisfied: scikit-learn in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (1.5.0)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Clustering ...\n",
      "Clustered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                              Article ID      Datum        Dan  Teden  \\\n",
       "0   001c7622-d40a-11ed-9d48-dfb487f9037c 2023-04-06  Thursday      14   \n",
       "1   00732997-d53a-11ed-9d48-dfb487f9037c 2023-04-07  Friday        14   \n",
       "2   01443cab-dbc6-11ed-9246-2b5ebef623ad 2023-04-15  Saturday      15   \n",
       "3   01e591ff-d2b1-11ed-83eb-0bd28cf4c8f0 2023-04-04  Tuesday       14   \n",
       "4   03e9491b-dd47-11ed-9246-2b5ebef623ad 2023-04-17  Monday        16   \n",
       "..                                   ...        ...        ...    ...   \n",
       "95  34ce443c-d2da-11ed-9f09-af460eec62b1 2023-04-04  Tuesday       14   \n",
       "96  35d75476-e0da-11ed-9f09-af460eec62b1 2023-04-22  Saturday      16   \n",
       "97  35e5b4e9-d511-11ed-9f09-af460eec62b1 2023-04-07  Friday        14   \n",
       "98  3632728f-d881-11ed-bfff-ed625638e8e4 2023-04-11  Tuesday       15   \n",
       "99  3632728f-d881-11ed-bfff-ed625638e8e4 2023-04-11  Tuesday       15   \n",
       "\n",
       "           Article created Tip medija Podtip medija  \\\n",
       "0  2023-04-06 01:31:33.498       tisk          tisk   \n",
       "1  2023-04-07 13:47:41.072   internet         splet   \n",
       "2  2023-04-15 21:44:58.961   internet         splet   \n",
       "3  2023-04-04 08:22:00.122       tisk          tisk   \n",
       "4  2023-04-17 19:40:59.639   internet         splet   \n",
       "..                     ...        ...           ...   \n",
       "95 2023-04-04 13:16:54.899   internet         splet   \n",
       "96 2023-04-22 08:52:12.915   internet         splet   \n",
       "97 2023-04-07 08:55:41.376   internet         splet   \n",
       "98 2023-04-11 17:54:59.000   internet         splet   \n",
       "99 2023-04-11 17:54:59.000   internet         splet   \n",
       "\n",
       "                              Media uuid        Medij  \\\n",
       "0   2fd717ed-78ba-4f63-b257-cd096acb6bda         Delo   \n",
       "1   754da261-9aee-4a1a-b9d8-734cd409fabf  Zurnal24.si   \n",
       "2   bc20546f-3a11-4061-90c2-2769468cd542      Delo.si   \n",
       "3   a67b08ee-a757-40ff-8d7e-ab8fc8246eec         Jana   \n",
       "4   754da261-9aee-4a1a-b9d8-734cd409fabf  Zurnal24.si   \n",
       "..                                   ...          ...   \n",
       "95  a180a2b9-f7f6-4d0e-8ad6-6a499ebb52b4       Sta.si   \n",
       "96  29213ab4-199c-4b11-aa64-eaa37092adf6    Rtvslo.si   \n",
       "97  d53a5e20-a6dd-4ca5-b989-2b662b028f7b     Siol.net   \n",
       "98  1b64e062-3e83-4591-af86-a6e244c45ed5     24ur.com   \n",
       "99  1b64e062-3e83-4591-af86-a6e244c45ed5     24ur.com   \n",
       "\n",
       "                             Rubric uuid  ... Osrednja tema Ključna sporočila  \\\n",
       "0   bc228842-98cc-48ea-8be9-0107becb707a  ...           NaN               NaN   \n",
       "1   e059ba7d-1a91-48f6-ac1c-d7ed703375ba  ...           NaN               NaN   \n",
       "2   f57a09ac-450d-4df4-bc2b-a2c7f96a4322  ...           NaN               NaN   \n",
       "3   4dd54f38-07e1-448f-b96d-dad85e669834  ...           NaN               NaN   \n",
       "4   e059ba7d-1a91-48f6-ac1c-d7ed703375ba  ...           NaN               NaN   \n",
       "..                                   ...  ...           ...               ...   \n",
       "95  38497701-d73e-48ef-bb6c-c660fd470426  ...           NaN               NaN   \n",
       "96  4676922b-91f3-430d-84b2-aefc0a25b76b  ...           NaN               NaN   \n",
       "97  68a138d9-919d-4311-a2c6-2074d0e7ee51  ...           NaN               NaN   \n",
       "98  d8078815-4303-4452-8337-9dff01493f9a  ...           NaN               NaN   \n",
       "99  d8078815-4303-4452-8337-9dff01493f9a  ...           NaN               NaN   \n",
       "\n",
       "            Fotografija   Omemba v naslovu  Omemba v podnaslovu  \\\n",
       "0   Vsebuje fotografijo  Omenjeno podjetje    Omenjeno podjetje   \n",
       "1   Vsebuje fotografijo  Omenjeno podjetje    Omenjeno podjetje   \n",
       "2   Vsebuje fotografijo  Omenjeno podjetje    Omenjeno podjetje   \n",
       "3   Vsebuje fotografijo  Omenjeno podjetje    Omenjeno podjetje   \n",
       "4   Vsebuje fotografijo  Omenjeno podjetje    Omenjeno podjetje   \n",
       "..                  ...                ...                  ...   \n",
       "95  Vsebuje fotografijo  Omenjeno podjetje    Omenjeno podjetje   \n",
       "96  Vsebuje fotografijo  Omenjeno podjetje    Omenjeno podjetje   \n",
       "97  Vsebuje fotografijo  Omenjeno podjetje    Omenjeno podjetje   \n",
       "98  Vsebuje fotografijo  Omenjeno podjetje    Omenjeno podjetje   \n",
       "99  Vsebuje fotografijo  Omenjeno podjetje    Omenjeno podjetje   \n",
       "\n",
       "                                                Tekst Month_Name  Year  \\\n",
       "0   V spomin Prof. dr. Marija Pečan, dr. med. (193...      April  2023   \n",
       "1   Člani Strateškega sveta za prehrano, ki je med...      April  2023   \n",
       "2   Člani komisije se niso opredeljevali do znakov...      April  2023   \n",
       "3   žJanimn jdrawiljfta Unija f 0  , Težave s ščit...      April  2023   \n",
       "4   \"Tudi vsi v zdravstvenem sistemu bodo dobili s...      April  2023   \n",
       "..                                                ...        ...   ...   \n",
       "95  Prodaja prehranskih dopolnil je vse bolj razši...      April  2023   \n",
       "96  Raziskujemo spanje. Vsi že poznamo spalne cikl...      April  2023   \n",
       "97  Termometer prikaže, kako vroč je članek. Skupn...      April  2023   \n",
       "98  SLOVENIJA\\n'Parkinsonova bolezen v našem siste...      April  2023   \n",
       "99  SLOVENIJA\\n'Parkinsonova bolezen v našem siste...      April  2023   \n",
       "\n",
       "                                            Embedding Cluster  \n",
       "0   [0.022848813, 0.050237596, 0.014087035, 0.0405...       0  \n",
       "1   [0.03551856, 0.073153414, -0.008020588, 0.0186...       1  \n",
       "2   [0.026685594, 0.04836063, 0.012246748, 0.00128...       2  \n",
       "3   [0.008627941, 0.038146276, -0.021161169, 0.014...       3  \n",
       "4   [0.036248676, 0.053472724, 0.01777791, 0.01507...       2  \n",
       "..                                                ...     ...  \n",
       "95  [0.036037818, 0.06924387, -0.01064763, 0.00568...      10  \n",
       "96  [0.017657526, 0.047999874, -0.0014392067, 0.01...      96  \n",
       "97  [0.012317047, 0.038933747, 0.016311843, 0.0406...       6  \n",
       "98  [0.005352284, 0.05056906, 0.0015653971, 0.0335...      50  \n",
       "99  [0.005352284, 0.05056906, 0.0015653971, 0.0335...      50  \n",
       "\n",
       "[100 rows x 84 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article ID</th>\n",
       "      <th>Datum</th>\n",
       "      <th>Dan</th>\n",
       "      <th>Teden</th>\n",
       "      <th>Article created</th>\n",
       "      <th>Tip medija</th>\n",
       "      <th>Podtip medija</th>\n",
       "      <th>Media uuid</th>\n",
       "      <th>Medij</th>\n",
       "      <th>Rubric uuid</th>\n",
       "      <th>...</th>\n",
       "      <th>Osrednja tema</th>\n",
       "      <th>Ključna sporočila</th>\n",
       "      <th>Fotografija</th>\n",
       "      <th>Omemba v naslovu</th>\n",
       "      <th>Omemba v podnaslovu</th>\n",
       "      <th>Tekst</th>\n",
       "      <th>Month_Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001c7622-d40a-11ed-9d48-dfb487f9037c</td>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-04-06 01:31:33.498</td>\n",
       "      <td>tisk</td>\n",
       "      <td>tisk</td>\n",
       "      <td>2fd717ed-78ba-4f63-b257-cd096acb6bda</td>\n",
       "      <td>Delo</td>\n",
       "      <td>bc228842-98cc-48ea-8be9-0107becb707a</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vsebuje fotografijo</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>V spomin Prof. dr. Marija Pečan, dr. med. (193...</td>\n",
       "      <td>April</td>\n",
       "      <td>2023</td>\n",
       "      <td>[0.022848813, 0.050237596, 0.014087035, 0.0405...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00732997-d53a-11ed-9d48-dfb487f9037c</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>Friday</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-04-07 13:47:41.072</td>\n",
       "      <td>internet</td>\n",
       "      <td>splet</td>\n",
       "      <td>754da261-9aee-4a1a-b9d8-734cd409fabf</td>\n",
       "      <td>Zurnal24.si</td>\n",
       "      <td>e059ba7d-1a91-48f6-ac1c-d7ed703375ba</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vsebuje fotografijo</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Člani Strateškega sveta za prehrano, ki je med...</td>\n",
       "      <td>April</td>\n",
       "      <td>2023</td>\n",
       "      <td>[0.03551856, 0.073153414, -0.008020588, 0.0186...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01443cab-dbc6-11ed-9246-2b5ebef623ad</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-04-15 21:44:58.961</td>\n",
       "      <td>internet</td>\n",
       "      <td>splet</td>\n",
       "      <td>bc20546f-3a11-4061-90c2-2769468cd542</td>\n",
       "      <td>Delo.si</td>\n",
       "      <td>f57a09ac-450d-4df4-bc2b-a2c7f96a4322</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vsebuje fotografijo</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Člani komisije se niso opredeljevali do znakov...</td>\n",
       "      <td>April</td>\n",
       "      <td>2023</td>\n",
       "      <td>[0.026685594, 0.04836063, 0.012246748, 0.00128...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01e591ff-d2b1-11ed-83eb-0bd28cf4c8f0</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-04-04 08:22:00.122</td>\n",
       "      <td>tisk</td>\n",
       "      <td>tisk</td>\n",
       "      <td>a67b08ee-a757-40ff-8d7e-ab8fc8246eec</td>\n",
       "      <td>Jana</td>\n",
       "      <td>4dd54f38-07e1-448f-b96d-dad85e669834</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vsebuje fotografijo</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>žJanimn jdrawiljfta Unija f 0  , Težave s ščit...</td>\n",
       "      <td>April</td>\n",
       "      <td>2023</td>\n",
       "      <td>[0.008627941, 0.038146276, -0.021161169, 0.014...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03e9491b-dd47-11ed-9246-2b5ebef623ad</td>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>Monday</td>\n",
       "      <td>16</td>\n",
       "      <td>2023-04-17 19:40:59.639</td>\n",
       "      <td>internet</td>\n",
       "      <td>splet</td>\n",
       "      <td>754da261-9aee-4a1a-b9d8-734cd409fabf</td>\n",
       "      <td>Zurnal24.si</td>\n",
       "      <td>e059ba7d-1a91-48f6-ac1c-d7ed703375ba</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vsebuje fotografijo</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>\"Tudi vsi v zdravstvenem sistemu bodo dobili s...</td>\n",
       "      <td>April</td>\n",
       "      <td>2023</td>\n",
       "      <td>[0.036248676, 0.053472724, 0.01777791, 0.01507...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>34ce443c-d2da-11ed-9f09-af460eec62b1</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-04-04 13:16:54.899</td>\n",
       "      <td>internet</td>\n",
       "      <td>splet</td>\n",
       "      <td>a180a2b9-f7f6-4d0e-8ad6-6a499ebb52b4</td>\n",
       "      <td>Sta.si</td>\n",
       "      <td>38497701-d73e-48ef-bb6c-c660fd470426</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vsebuje fotografijo</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Prodaja prehranskih dopolnil je vse bolj razši...</td>\n",
       "      <td>April</td>\n",
       "      <td>2023</td>\n",
       "      <td>[0.036037818, 0.06924387, -0.01064763, 0.00568...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>35d75476-e0da-11ed-9f09-af460eec62b1</td>\n",
       "      <td>2023-04-22</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>16</td>\n",
       "      <td>2023-04-22 08:52:12.915</td>\n",
       "      <td>internet</td>\n",
       "      <td>splet</td>\n",
       "      <td>29213ab4-199c-4b11-aa64-eaa37092adf6</td>\n",
       "      <td>Rtvslo.si</td>\n",
       "      <td>4676922b-91f3-430d-84b2-aefc0a25b76b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vsebuje fotografijo</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Raziskujemo spanje. Vsi že poznamo spalne cikl...</td>\n",
       "      <td>April</td>\n",
       "      <td>2023</td>\n",
       "      <td>[0.017657526, 0.047999874, -0.0014392067, 0.01...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>35e5b4e9-d511-11ed-9f09-af460eec62b1</td>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>Friday</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-04-07 08:55:41.376</td>\n",
       "      <td>internet</td>\n",
       "      <td>splet</td>\n",
       "      <td>d53a5e20-a6dd-4ca5-b989-2b662b028f7b</td>\n",
       "      <td>Siol.net</td>\n",
       "      <td>68a138d9-919d-4311-a2c6-2074d0e7ee51</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vsebuje fotografijo</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Termometer prikaže, kako vroč je članek. Skupn...</td>\n",
       "      <td>April</td>\n",
       "      <td>2023</td>\n",
       "      <td>[0.012317047, 0.038933747, 0.016311843, 0.0406...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3632728f-d881-11ed-bfff-ed625638e8e4</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-04-11 17:54:59.000</td>\n",
       "      <td>internet</td>\n",
       "      <td>splet</td>\n",
       "      <td>1b64e062-3e83-4591-af86-a6e244c45ed5</td>\n",
       "      <td>24ur.com</td>\n",
       "      <td>d8078815-4303-4452-8337-9dff01493f9a</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vsebuje fotografijo</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>SLOVENIJA\\n'Parkinsonova bolezen v našem siste...</td>\n",
       "      <td>April</td>\n",
       "      <td>2023</td>\n",
       "      <td>[0.005352284, 0.05056906, 0.0015653971, 0.0335...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3632728f-d881-11ed-bfff-ed625638e8e4</td>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-04-11 17:54:59.000</td>\n",
       "      <td>internet</td>\n",
       "      <td>splet</td>\n",
       "      <td>1b64e062-3e83-4591-af86-a6e244c45ed5</td>\n",
       "      <td>24ur.com</td>\n",
       "      <td>d8078815-4303-4452-8337-9dff01493f9a</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vsebuje fotografijo</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>Omenjeno podjetje</td>\n",
       "      <td>SLOVENIJA\\n'Parkinsonova bolezen v našem siste...</td>\n",
       "      <td>April</td>\n",
       "      <td>2023</td>\n",
       "      <td>[0.005352284, 0.05056906, 0.0015653971, 0.0335...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 84 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# Assuming your data variable is a DataFrame that you have already prepared\n",
    "# Continuing from the last step of the previous script\n",
    "\n",
    "# Convert the date strings back to datetime objects\n",
    "data['Datum'] = pd.to_datetime(data['Datum'], format='%Y-%m-%d')\n",
    "\n",
    "# Extract the month name and year for easy filtering\n",
    "data['Month_Name'] = data['Datum'].dt.month_name()\n",
    "data['Year'] = data['Datum'].dt.year\n",
    "\n",
    "# Get the month name and year of the last row\n",
    "zadnji_mesec = data['Month_Name'].iloc[-1]\n",
    "leto = data['Year'].iloc[-1]\n",
    "\n",
    "# Filter data for the last month and year\n",
    "filtered_data_zadnji = data[(data['Month_Name'] == zadnji_mesec) & (data['Year'] == leto)]\n",
    "\n",
    "# Remove duplicates based on 'Article ID' before grouping\n",
    "filtered_data_zadnji_unique = filtered_data_zadnji.drop_duplicates(subset='Article ID')\n",
    "\n",
    "# Assign week number to each date in the last month\n",
    "filtered_data_zadnji_unique['Week_Number'] = filtered_data_zadnji_unique['Datum'].dt.isocalendar().week\n",
    "\n",
    "# Group by week number and count unique 'Article ID'\n",
    "unique_article_by_week = filtered_data_zadnji_unique.groupby('Week_Number')['Article ID'].nunique()\n",
    "\n",
    "# Find the week with the maximum count of unique 'Article ID'\n",
    "max_articles_week = unique_article_by_week.idxmax()\n",
    "max_articles_count = unique_article_by_week[max_articles_week]\n",
    "\n",
    "# Calculate the min and max date for the week with maximum unique 'Article ID'\n",
    "week_dates = filtered_data_zadnji_unique[filtered_data_zadnji_unique['Week_Number'] == max_articles_week]['Datum']\n",
    "min_date = week_dates.min()\n",
    "max_date = week_dates.max()\n",
    "\n",
    "# Group by date within the max week and count unique 'Article ID'\n",
    "daily_counts = filtered_data_zadnji_unique[filtered_data_zadnji_unique['Week_Number'] == max_articles_week].groupby('Datum')['Article ID'].nunique()\n",
    "\n",
    "# Find the day with the maximum count of unique 'Article ID'\n",
    "max_articles_day = daily_counts.idxmax()\n",
    "max_articles_day_count = daily_counts[max_articles_day]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Week with maximum unique Article ID: Week {max_articles_week} with {max_articles_count} unique Article IDs\")\n",
    "print(f\"Minimum date in this week: {min_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Maximum date in this week: {max_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Day with the most Article IDs in this week: {max_articles_day.strftime('%Y-%m-%d')} with {max_articles_day_count} unique Article IDs\")\n",
    "\n",
    "# Step 1: Filter data for the specific week with the maximum unique Article ID\n",
    "week_data = filtered_data_zadnji_unique[filtered_data_zadnji_unique['Week_Number'] == max_articles_week]\n",
    "\n",
    "# Group by 'Cluster' and count unique 'Article ID' in each\n",
    "cluster_article_counts = week_data.groupby('Cluster')['Article ID'].nunique()\n",
    "\n",
    "# Sort clusters by their counts in descending order\n",
    "sorted_clusters = cluster_article_counts.sort_values(ascending=False)\n",
    "\n",
    "# Filter out clusters where the unique 'Article ID' count is 1\n",
    "filtered_clusters = sorted_clusters[sorted_clusters > 1]\n",
    "\n",
    "# Calculate the top 20% of clusters\n",
    "top_20_percent_index = int(len(filtered_clusters) * 0.2)\n",
    "\n",
    "# Get the top 20% clusters by unique 'Article ID' count\n",
    "top_20_percent_clusters = filtered_clusters.head(top_20_percent_index)\n",
    "\n",
    "# Filter the week data to include only the top 20% clusters\n",
    "final_filtered_data = week_data[week_data['Cluster'].isin(top_20_percent_clusters.index)]\n"
   ],
   "metadata": {
    "id": "67vlXzIQJoEN",
    "ExecuteTime": {
     "end_time": "2024-06-13T06:01:26.064892Z",
     "start_time": "2024-06-13T06:01:26.032399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week with maximum unique Article ID: Week 17 with 138 unique Article IDs\n",
      "Minimum date in this week: 2024-04-22\n",
      "Maximum date in this week: 2024-04-28\n",
      "Day with the most Article IDs in this week: 2024-04-22 with 33 unique Article IDs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_647601/3915993939.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data_zadnji_unique['Week_Number'] = filtered_data_zadnji_unique['Datum'].dt.isocalendar().week\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install openai\n"
   ],
   "metadata": {
    "id": "HgLcv3ySFu14",
    "ExecuteTime": {
     "end_time": "2024-06-13T06:01:29.016608Z",
     "start_time": "2024-06-13T06:01:26.066384Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (1.33.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (4.4.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (2.7.3)\r\n",
      "Requirement already satisfied: sniffio in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (1.3.1)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from openai) (4.12.2)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\r\n",
      "Requirement already satisfied: certifi in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /home/nikola/projects/emma/.venv/klusters/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "source": [
    "import openai\n",
    "import os"
   ],
   "metadata": {
    "id": "zugy_QWbFwLT",
    "ExecuteTime": {
     "end_time": "2024-06-13T06:01:29.031708Z",
     "start_time": "2024-06-13T06:01:29.023175Z"
    }
   },
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai_organization = os.getenv('OPENAI_ORG_ID')"
   ],
   "metadata": {
    "id": "st6nJFeYFxdQ",
    "ExecuteTime": {
     "end_time": "2024-06-13T06:01:29.060016Z",
     "start_time": "2024-06-13T06:01:29.034961Z"
    }
   },
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# Assuming your final_filtered_data is already prepared\n",
    "# Create a combined text column\n",
    "final_filtered_data['Combined Text'] = final_filtered_data['Naslov objave'] + ' ' + final_filtered_data['Tekst']\n",
    "\n",
    "# Function to call OpenAI API\n",
    "def call_chat_model(messages, temperature=0, max_tokens=400, top_p=1, frequency_penalty=0, presence_penalty=0, model=\"gpt-4o\"):\n",
    "    URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"top_p\": top_p,\n",
    "        \"frequency_penalty\": frequency_penalty,\n",
    "        \"presence_penalty\": presence_penalty\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Summarize each row separately\n",
    "summaries = []\n",
    "\n",
    "for idx, row in final_filtered_data.iterrows():\n",
    "    combined_text = row['Combined Text']\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Tvoja naloga je branje in povzemanje člankov v eni povedi. Ta poved odgovori na vprašanje, o čem govorijo podana besedila za naročnika. Ne smeš delati predpostavk ali generirati vsebine, ki ni neposredno podprta z besedilom članka. Tvoji povzetki naj bodo ekvivalent različice člankov \\\"TL;DR\\\" (Preveč dolgo; Nisem bral). Poskrbi, da bodo tvoji odgovori temeljili izključno na podlagi podaneih besedil in ne vključujejo osebnih interpretacij ali mnenj. Omejitev odgovora naj bo na 250 znakov.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"V 250 znakih napiši, o čem govorijo besedila v: {combined_text}\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = call_chat_model(messages)\n",
    "    summary = response['choices'][0]['message']['content']\n",
    "    summaries.append(summary)\n",
    "\n",
    "# Combine summaries into a single text\n",
    "combined_summaries = \" \".join(summaries)\n",
    "\n",
    "# Final summary of summaries\n",
    "final_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\":  f\"Si medijski analitik z odličnim znanjem slovnice. Besedilo smiselno slovnično popravi, kjer je potrebno. Tvoja naloga je branje in povzemanje večih člankov v eni povedi za naročnika {entiteta}. Ta poved odgovori na vprašanje, o čem govorijo podana besedila za naročnika. Ne smeš delati predpostavk ali generirati vsebine, ki ni neposredno podprta z besedilom članka. Tvoji povzetki naj bodo ekvivalent različice člankov \\\"TL;DR\\\" (Preveč dolgo; Nisem bral). Poskrbi, da bodo tvoji odgovori temeljili izključno na podlagi podaneih besedil in ne vključujejo osebnih interpretacij ali mnenj. Omejitev odgovora naj bo na 250 znakov.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"V 400 znakih napiši, o čem govorijo besedila v: {combined_summaries}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "final_response = call_chat_model(final_messages)\n",
    "final_summary = final_response['choices'][0]['message']['content']\n",
    "\n",
    "# Print the final summary\n",
    "print(final_summary)\n"
   ],
   "metadata": {
    "id": "W1SeeFWOF0NI",
    "ExecuteTime": {
     "end_time": "2024-06-13T06:01:29.565660Z",
     "start_time": "2024-06-13T06:01:29.063997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_647601/3061831978.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_filtered_data['Combined Text'] = final_filtered_data['Naslov objave'] + ' ' + final_filtered_data['Tekst']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[79], line 49\u001B[0m\n\u001B[1;32m     37\u001B[0m     messages \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     38\u001B[0m         {\n\u001B[1;32m     39\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     45\u001B[0m         }\n\u001B[1;32m     46\u001B[0m     ]\n\u001B[1;32m     48\u001B[0m     response \u001B[38;5;241m=\u001B[39m call_chat_model(messages)\n\u001B[0;32m---> 49\u001B[0m     summary \u001B[38;5;241m=\u001B[39m \u001B[43mresponse\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mchoices\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     50\u001B[0m     summaries\u001B[38;5;241m.\u001B[39mappend(summary)\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# Combine summaries into a single text\u001B[39;00m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'choices'"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "source": [
    "# Filter data by 'Naklonjenost tematike' == 'Nenaklonjeno'\n",
    "nenaklonjeno_data = filtered_data_zadnji_unique[filtered_data_zadnji_unique['Naklonjenost tematike'] == 'Nenaklonjeno']\n",
    "\n",
    "# Calculate the number of words in the 'Tekst' column for each row\n",
    "nenaklonjeno_data['Word_Count'] = nenaklonjeno_data['Tekst'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Group by 'Cluster' and count unique 'Article ID' in each\n",
    "cluster_article_counts = nenaklonjeno_data.groupby('Cluster')['Article ID'].nunique()\n",
    "\n",
    "# Sort clusters by their counts in descending order\n",
    "sorted_clusters = cluster_article_counts.sort_values(ascending=False)\n",
    "\n",
    "# Ensure we have at least 3 clusters\n",
    "percentage = 0.5\n",
    "while len(sorted_clusters.head(int(len(sorted_clusters) * percentage))) < 3 and percentage <= 1:\n",
    "    percentage += 0.1\n",
    "\n",
    "# Calculate the top percentage of clusters (ensuring at least 3 clusters)\n",
    "top_percent_index = int(len(sorted_clusters) * percentage)\n",
    "\n",
    "# Get the top clusters by unique 'Article ID' count\n",
    "top_clusters = sorted_clusters.head(top_percent_index)\n",
    "\n",
    "# Filter the data to include only the top clusters\n",
    "filtered_nenaklonjeno_top = nenaklonjeno_data[nenaklonjeno_data['Cluster'].isin(top_clusters.index)]\n",
    "\n",
    "# Group by 'Cluster' and find the 'Article ID' with the highest word count in the 'Tekst' column for each cluster\n",
    "max_word_count_by_cluster = filtered_nenaklonjeno_top.loc[filtered_nenaklonjeno_top.groupby('Cluster')['Word_Count'].idxmax()]\n",
    "\n",
    "# Save the final filtered data into a new variable\n",
    "final_filtered_nenaklonjeno = max_word_count_by_cluster\n",
    "\n",
    "# Display the final filtered dataset\n",
    "print(final_filtered_nenaklonjeno)\n",
    "\n",
    "final_filtered_nenaklonjeno\n"
   ],
   "metadata": {
    "id": "TYZ7eU__RNVm"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a combined text column\n",
    "final_filtered_nenaklonjeno['Combined Text'] = final_filtered_nenaklonjeno['Naslov objave'] + ' ' + final_filtered_nenaklonjeno['Tekst']\n",
    "\n",
    "# Function to call OpenAI API\n",
    "def call_chat_model(messages, temperature=0, max_tokens=400, top_p=1, frequency_penalty=0, presence_penalty=0, model=\"gpt-4o\"):\n",
    "    URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"top_p\": top_p,\n",
    "        \"frequency_penalty\": frequency_penalty,\n",
    "        \"presence_penalty\": presence_penalty\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Summarize each row separately\n",
    "nenaklonjeno_summaries = []\n",
    "\n",
    "for idx, row in final_filtered_nenaklonjeno.iterrows():\n",
    "    combined_text = row['Combined Text']\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\":  f\" Si medijski analitik, ki dela za kliping agencijo z odličnim znanjem slovnice. Besedilo smiselno slovnično popravi, kjer je potrebno. Tvoja naloga je branje in povzemanje večih člankov v eni povedi za naročnika {entiteta}. Ta poved odgovori na vprašanje, o čem govorijo podana besedila za naročnika. Ne smeš delati predpostavk ali generirati vsebine, ki ni neposredno podprta z besedilom članka. Tvoji povzetki naj bodo ekvivalent različice člankov \\\"TL;DR\\\" (Preveč dolgo; Nisem bral). Poskrbi, da bodo tvoji odgovori temeljili izključno na podlagi podaneih besedil in ne vključujejo osebnih interpretacij ali mnenj. Omejitev odgovora naj bo na 250 znakov.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"V 250 znakih napiši, o čem govorijo besedila v: {combined_text}\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = call_chat_model(messages)\n",
    "    summary = response['choices'][0]['message']['content']\n",
    "    nenaklonjeno_summaries.append(summary)\n",
    "\n",
    "# Combine summaries into a single text\n",
    "combined_nenaklonjeno_summaries = \" \".join(nenaklonjeno_summaries)\n",
    "\n",
    "# Final summary of summaries\n",
    "final_nenaklonjeno_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Tvoja naloga je branje in povzemanje večih člankov v eni povedi. Ta poved odgovori na vprašanje, o čem govorijo podana besedila za naročnika. Ne smeš delati predpostavk ali generirati vsebine, ki ni neposredno podprta z besedilom članka. Tvoji povzetki naj bodo ekvivalent različice člankov \\\"TL;DR\\\" (Preveč dolgo; Nisem bral). Poskrbi, da bodo tvoji odgovori temeljili izključno na podlagi podaneih besedil in ne vključujejo osebnih interpretacij ali mnenj. Omejitev odgovora naj bo na 250 znakov.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"V 400 znakih napiši, o čem govorijo besedila v: {combined_nenaklonjeno_summaries}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "final_nenaklonjeno_response = call_chat_model(final_nenaklonjeno_messages)\n",
    "final_nenaklonjeno_summary = final_nenaklonjeno_response['choices'][0]['message']['content']\n",
    "\n",
    "# Print the final summary\n",
    "print(final_nenaklonjeno_summary)"
   ],
   "metadata": {
    "id": "OB8HG994Sus0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Filter data by 'Naklonjenost tematike' == 'Naklonjeno'\n",
    "naklonjeno_data = filtered_data_zadnji_unique[filtered_data_zadnji_unique['Naklonjenost tematike'] == 'Naklonjeno']\n",
    "\n",
    "# Calculate the number of words in the 'Tekst' column for each row\n",
    "naklonjeno_data['Word_Count'] = naklonjeno_data['Tekst'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Group by 'Cluster' and count unique 'Article ID' in each\n",
    "cluster_article_counts_naklonjeno = naklonjeno_data.groupby('Cluster')['Article ID'].nunique()\n",
    "\n",
    "# Sort clusters by their counts in descending order\n",
    "sorted_clusters_naklonjeno = cluster_article_counts_naklonjeno.sort_values(ascending=False)\n",
    "\n",
    "# Ensure we have at least 3 clusters\n",
    "percentage_naklonjeno = 0.5\n",
    "while len(sorted_clusters_naklonjeno.head(int(len(sorted_clusters_naklonjeno) * percentage_naklonjeno))) < 3 and percentage_naklonjeno <= 1:\n",
    "    percentage_naklonjeno += 0.1\n",
    "\n",
    "# Calculate the top percentage of clusters (ensuring at least 3 clusters)\n",
    "top_percent_index_naklonjeno = int(len(sorted_clusters_naklonjeno) * percentage_naklonjeno)\n",
    "\n",
    "# Get the top clusters by unique 'Article ID' count\n",
    "top_clusters_naklonjeno = sorted_clusters_naklonjeno.head(top_percent_index_naklonjeno)\n",
    "\n",
    "# Filter the data to include only the top clusters\n",
    "filtered_naklonjeno_top = naklonjeno_data[naklonjeno_data['Cluster'].isin(top_clusters_naklonjeno.index)]\n",
    "\n",
    "# Group by 'Cluster' and find the 'Article ID' with the highest word count in the 'Tekst' column for each cluster\n",
    "max_word_count_by_cluster_naklonjeno = filtered_naklonjeno_top.loc[filtered_naklonjeno_top.groupby('Cluster')['Word_Count'].idxmax()]\n",
    "\n",
    "# Save the final filtered data into a new variable\n",
    "final_filtered_naklonjeno = max_word_count_by_cluster_naklonjeno\n",
    "\n",
    "# Display the final filtered dataset\n",
    "print(final_filtered_naklonjeno)\n"
   ],
   "metadata": {
    "id": "RogZai3JWcZ7"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a combined text column\n",
    "final_filtered_naklonjeno['Combined Text'] = final_filtered_naklonjeno['Naslov objave'] + ' ' + final_filtered_naklonjeno['Tekst']\n",
    "\n",
    "# Function to call OpenAI API\n",
    "def call_chat_model(messages, temperature=0, max_tokens=400, top_p=1, frequency_penalty=0, presence_penalty=0, model=\"gpt-4o\"):\n",
    "    URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"top_p\": top_p,\n",
    "        \"frequency_penalty\": frequency_penalty,\n",
    "        \"presence_penalty\": presence_penalty\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Summarize each row separately\n",
    "naklonjeno_summaries = []\n",
    "\n",
    "for idx, row in final_filtered_naklonjeno.iterrows():\n",
    "    combined_text = row['Combined Text']\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Tvoja naloga je branje in povzemanje člankov v eni povedi. Ta poved odgovori na vprašanje, o čem govorijo podana besedila za naročnika. Ne smeš delati predpostavk ali generirati vsebine, ki ni neposredno podprta z besedilom članka. Tvoji povzetki naj bodo ekvivalent različice člankov \\\"TL;DR\\\" (Preveč dolgo; Nisem bral). Poskrbi, da bodo tvoji odgovori temeljili izključno na podlagi podaneih besedil in ne vključujejo osebnih interpretacij ali mnenj. Omejitev odgovora naj bo na 250 znakov.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"V 250 znakih napiši, o čem govorijo besedila v: {combined_text}\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = call_chat_model(messages)\n",
    "    summary = response['choices'][0]['message']['content']\n",
    "    naklonjeno_summaries.append(summary)\n",
    "\n",
    "# Combine summaries into a single text\n",
    "combined_naklonjeno_summaries = \" \".join(naklonjeno_summaries)\n",
    "\n",
    "# Final summary of summaries\n",
    "final_naklonjeno_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Si medijski analitik, ki dela za kliping agencijo z odličnim znanjem slovnice. Besedilo smiselno slovnično popravi, kjer je potrebno.Tvoja naloga je branje in povzemanje večih člankov v eni povedi za naročnika {entiteta}. Ta poved odgovori na vprašanje, o čem govorijo podana besedila za naročnika. Ne smeš delati predpostavk ali generirati vsebine, ki ni neposredno podprta z besedilom članka. Tvoji povzetki naj bodo ekvivalent različice člankov \\\"TL;DR\\\" (Preveč dolgo; Nisem bral). Poskrbi, da bodo tvoji odgovori temeljili izključno na podlagi podaneih besedil in ne vključujejo osebnih interpretacij ali mnenj. Omejitev odgovora naj bo na 250 znakov.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"V 400 znakih napiši, o čem govorijo besedila v: {combined_naklonjeno_summaries}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "final_naklonjeno_response = call_chat_model(final_naklonjeno_messages)\n",
    "final_naklonjeno_summary = final_naklonjeno_response['choices'][0]['message']['content']\n",
    "\n",
    "# Print the final summary\n",
    "print(final_naklonjeno_summary)"
   ],
   "metadata": {
    "id": "IhF6i2OhWhFJ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# Assuming the OpenAI API has been called and the responses are available\n",
    "# Replace the dummy text with actual responses if needed\n",
    "\n",
    "# These should be the actual summaries extracted from the responses\n",
    "final_summary = final_response['choices'][0]['message']['content']\n",
    "final_nenaklonjeno_summary = final_nenaklonjeno_response['choices'][0]['message']['content']\n",
    "final_naklonjeno_summary = final_naklonjeno_response['choices'][0]['message']['content']\n",
    "\n",
    "# Combine the summaries into a single text\n",
    "combined_summaries = f\"{final_summary} {final_nenaklonjeno_summary} {final_naklonjeno_summary}\"\n",
    "\n",
    "# Function to call OpenAI API\n",
    "def call_chat_model(messages, temperature=0, max_tokens=800, top_p=1, frequency_penalty=0, presence_penalty=0, model=\"gpt-4o\"):\n",
    "    URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"top_p\": top_p,\n",
    "        \"frequency_penalty\": frequency_penalty,\n",
    "        \"presence_penalty\": presence_penalty\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Final summary of all summaries\n",
    "final_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Si medijski analitik, ki dela za kliping agencijo z odličnim znanjem slovnice. Besedilo smiselno slovnično popravi, kjer je potrebno. Tvoja naloga je branje in povzemanje večih člankov. Ta poved odgovori na vprašanje, o čem so govorile medijske objave v preteklem mesecu za {entiteta}. Ne smeš delati predpostavk ali generirati vsebine, ki ni neposredno podprta z besedilom članka. Tvoji povzetki naj bodo ekvivalent različice člankov \\\"TL;DR\\\" (Preveč dolgo; Nisem bral). Poskrbi, da bodo tvoji odgovori temeljili izključno na podlagi podaneih besedil in ne vključujejo osebnih interpretacij ali mnenj.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Napiši 3 povedi, o čem govorijo {combined_summaries}. Nadaljuj poved:Mediji so v {zadnji_mesec_leto} največ pozornosti namenili ... \"\n",
    "    }\n",
    "]\n",
    "\n",
    "final_response = call_chat_model(final_messages)\n",
    "final_combined_summary = final_response['choices'][0]['message']['content']\n",
    "\n",
    "# Print the final summary of summaries\n",
    "print(final_combined_summary)\n"
   ],
   "metadata": {
    "id": "uQIwJ2i-YvTJ"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "a = (\n",
    "    f\" V {zadnji_mesec_leto} smo zaznali {unique_uuids_zadnji} objav, kar je {percentage_difference} % manj kot v istem obdobju lani.\"\n",
    "    f\" Bruto vrednost medijskih objav je bila večja/manjša za {percentage_difference_value} %.\"\n",
    "    f\" {percentage_nevtralno_objave:.1f} % objav je bilo nevtralnih, {percentage_naklonjeno_objave:.1f} % naklonjenih in {percentage_nenaklonjeno_objave:.1f} % nenaklonjenih.\"\n",
    "    f\" {percentage_internet} objav smo zasledili na spletu, {percentage_tisk} v tisku, {percentage_tv} na televiziji in {percentage_radio} na radiju.\"\n",
    "    f\" Ločeno po lokalnosti medijev, smo zaznali {unique_article_by_lokalnost_str} objav. V regionalnih medijih so poročali {unique_article_by_medij_str}.\"\n",
    "    f\" Mediji so v {zadnji_mesec_leto} največ pozornosti namenili {final_combined_summary}\"\n",
    ")\n"
   ],
   "metadata": {
    "id": "LVB7PFoqixpO"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(a)"
   ],
   "metadata": {
    "id": "Z20NY457ku8A"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import openai\n",
    "import json\n",
    "\n",
    "def call_chat_model(messages, temperature=0, max_tokens=1000, top_p=1, frequency_penalty=0, presence_penalty=0, model=\"gpt-4o\"):\n",
    "    URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"top_p\": top_p,\n",
    "        \"frequency_penalty\": frequency_penalty,\n",
    "        \"presence_penalty\": presence_penalty\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "\n",
    "# Setup messages\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Si medijski analitik z odličnim znanjem slovnice. Za naročnika si prejel ključne medijske podatke in zanj pišeš interpretacijo podatkov. Pišeš v tretji osebi. Besedilo smiselno slovnično popravi, kjer je potrebno. Vsa števila v obliki, (1), (2), (3) pusti. Besedilo loči v tri (3) odstavke. Pri decimalkah uporabi vejico (,), tistočice loči s piko (.). Ko uporabljaš procente (%), po številki naredi presledek. Podatke, kjer je število objav samo ena (1), smiselno uporabi. Pazi na ponavljanje besed oziroma raznolikost in ustreznost besedišča. Ne dodajaj ničesar in uporabi zgolj podane podatke.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\" Smiselno slovnično popravi besedilo v {a}. \"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Call the model\n",
    "response_a = call_chat_model(messages)\n",
    "\n"
   ],
   "metadata": {
    "id": "riK6LV85pQca"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Print the response content\n",
    "print(response_a.get('choices', [{}])[0].get('message', {}).get('content', 'No response found.'))"
   ],
   "metadata": {
    "id": "iZp2CLY7pVi5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "b = (\n",
    "    f\" V {zadnji_mesec_leto} smo največ objav v enem tednu ({max_articles_count}) zaznali med {min_date.strftime('%Y-%m-%d')} in {max_date.strftime('%Y-%m-%d')}.\"\n",
    "    f\" Takrat je največ medijev poročalo o {final_summary}. Vrh poročanja omenjenega tedna smo zaznali {max_articles_day.strftime('%Y-%m-%d')} s {max_articles_day_count} objavami.\"\n",
    "    f\" Nenaklonjene objave so se v tem mesecu navezovale predvsem na {final_nenaklonjeno_summary}.\"\n",
    "    f\" Naklonjene objave pa se govorile o {final_naklonjeno_summary}.\"\n",
    ")\n"
   ],
   "metadata": {
    "id": "klQCoIY6zlr4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(b)"
   ],
   "metadata": {
    "id": "BjL7PPQy0bPE"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import openai\n",
    "import json\n",
    "\n",
    "def call_chat_model(messages, temperature=0, max_tokens=1000, top_p=1, frequency_penalty=0, presence_penalty=0, model=\"gpt-4o\"):\n",
    "    URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"top_p\": top_p,\n",
    "        \"frequency_penalty\": frequency_penalty,\n",
    "        \"presence_penalty\": presence_penalty\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "\n",
    "# Setup messages\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Si medijski analitik z odličnim znanjem slovnice. Za naročnika si prejel ključne medijske podatke in zanj pišeš interpretacijo podatkov. Pišeš v tretji osebi. Besedilo smiselno slovnično popravi, kjer je potrebno. Vsa števila v obliki, (1), (2), (3) pusti. Besedilo loči v tri (3) odstavke. Pri decimalkah uporabi vejico (,), tistočice loči s piko (.). Ko uporabljaš procente (%), po številki naredi presledek. Podatke, kjer je število objav samo ena (1), smiselno uporabi. Pazi na ponavljanje besed oziroma raznolikost in ustreznost besedišča. Ne dodajaj ničesar in uporabi zgolj podane podatke.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\" Smiselno slovnično popravi besedilo v {b}. \"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Call the model\n",
    "response_b = call_chat_model(messages)\n",
    "\n"
   ],
   "metadata": {
    "id": "J1nCze_v4nVN"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Print the response content\n",
    "print(response_b.get('choices', [{}])[0].get('message', {}).get('content', 'No response found.'))"
   ],
   "metadata": {
    "id": "9qmOuzcT4sU7"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
