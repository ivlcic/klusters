{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ElasticSearch Obstoječi vektorji\n",
    "Če imaš težave z računanjem vektorjev; Pokličeš Elasticsearch.   \n",
    "Spet kličem vektorizacijo na stolpcu 'Text' in dobim stolpec z vektorjem 'Embedding'"
   ],
   "id": "b5ce91f09b70d3f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install pandas numpy networkx numpy scikit-learn requests",
   "id": "79e1b30f41c98ca0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel(os.path.join('..', 'data', 'Reworkan data 4.xlsx'))\n",
    "data.head()"
   ],
   "id": "912cef934ed4f337",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "V realnem projektu, pazi na okoljske spremeljivke",
   "id": "20bd7ebd46eddccd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'CPTM_SPASS is set: {len(os.getenv(\"CPTM_SPASS\"))}')\n",
    "print(f'CPTM_SURL is set: {len(os.getenv(\"CPTM_SURL\"))}')\n",
    "print(f'CPTM_SUSER is set: {len(os.getenv(\"CPTM_SUSER\"))}')"
   ],
   "id": "1a916cccf53077a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Funkcije za pridobivanje že obstoječih vektorjev iz elastike.",
   "id": "b4af254a9d72b6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy\n",
    "import json\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "def embed_elastic(df: pd.DataFrame, col_name: str = 'Tekst', target_col_name: str = 'Embedding') -> pd.DataFrame:\n",
    "    # Split the DataFrame into batches of 500 rows\n",
    "    batch_size = 1000\n",
    "    num_batches = (len(df) + batch_size - 1) // batch_size\n",
    "    es_column = 'vector_768___textonic_v2'\n",
    "    id_column = 'Article ID'\n",
    "    \n",
    "    responses = pd.DataFrame()\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = (i + 1) * batch_size\n",
    "        \n",
    "        batch = df[id_column].iloc[start_idx:end_idx].tolist()\n",
    "        \n",
    "        query = '''\n",
    "        {\n",
    "          \"query\": {\n",
    "            \"bool\": {\n",
    "              \"filter\": [\n",
    "                {\"range\": {\"created\": {\"gte\": \"1996-01-01\", \"lt\": \"2030-01-01\"}}},\n",
    "                {\"terms\": {\"uuid\": ''' + json.dumps(batch) + '''}}\n",
    "              ]\n",
    "            }\n",
    "          },\n",
    "          \"_source\": [\"uuid\", ''' + json.dumps(es_column) + '''],\n",
    "          \"from\": 0, \"size\": 1000, \"sort\": { \"created\": {\"order\": \"asc\"}}\n",
    "        }\n",
    "        '''\n",
    "        \n",
    "        result = {\n",
    "            id_column: [],\n",
    "            target_col_name: []\n",
    "        }\n",
    "        # Call the remote service for the current batch\n",
    "        resp_text = ''\n",
    "        try:\n",
    "            resp = requests.post(os.getenv(\"CPTM_SURL\"),\n",
    "                                 headers={'Content-Type': 'application/json'},\n",
    "                                 auth=HTTPBasicAuth(os.getenv(\"CPTM_SUSER\"), os.getenv(\"CPTM_SPASS\")),\n",
    "                                 data=query)\n",
    "            resp_text = json.loads(resp.text)\n",
    "            for hit in resp_text['hits']['hits']:\n",
    "                if es_column not in hit['_source']:\n",
    "                    continue\n",
    "                if 'uuid' not in hit['_source']:\n",
    "                    continue\n",
    "                vect = numpy.array(hit['_source'][es_column])  # here is article vector\n",
    "                result[id_column].append(hit['_source']['uuid'])  # here is uuid of an article \n",
    "                result[target_col_name].append(vect)\n",
    "            print(f'Requested/received/valid vector : {len(batch)}/{len(resp_text[\"hits\"][\"hits\"])}/{len(result[target_col_name])}')\n",
    "        except Exception as error:\n",
    "            print(f'Elasticsearch request error [{error}] for query [{query}] with response [{resp_text}]')\n",
    "            return df\n",
    "        \n",
    "        # Convert the collected responses to a DataFrame\n",
    "        response_df = pd.DataFrame(result)\n",
    "        responses = pd.concat([responses, response_df])\n",
    "        \n",
    "    # Merge the responses back into the original DataFrame\n",
    "    orig_len = len(df)\n",
    "    df = pd.merge(df, responses, on=id_column, how='left').dropna(subset=[target_col_name])\n",
    "    print(f'Requested/Successful {orig_len}/{len(df)}')\n",
    "    return df"
   ],
   "id": "3bd2621f2d5b856a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Kličem vektorizacijo na stolpcu 'Text' in dobim stolpec z vektorjem 'Embedding'",
   "id": "6248742bae82169c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = embed_elastic(data, 'Tekst', 'Embedding')\n",
    "data[['Article ID', 'Datum', 'Medij', 'Tekst', 'Embedding']].head(100)"
   ],
   "id": "6bb737632c935461",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definiram funkcijo za cluster",
   "id": "be7c8b653ddc137b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cluster_louvain(df: pd.DataFrame, col_name: str = 'Embedding', similarity_threshold: float = 0.96):\n",
    "    print(\"Clustering ...\")\n",
    "    embeddings = np.array(df[col_name].to_list())\n",
    "    labels = [0] * len(embeddings)\n",
    "    x = cosine_similarity(embeddings, embeddings)\n",
    "    similarity_matrix = x > similarity_threshold\n",
    "    graph = nx.from_numpy_array(similarity_matrix)\n",
    "    communities = nx.algorithms.community.louvain_communities(graph, resolution=0.1)\n",
    "    for community in communities:\n",
    "        initial_member = min(community)\n",
    "        for member in community:\n",
    "            labels[member] = initial_member\n",
    "\n",
    "    df['Cluster'] = pd.Series(labels)\n",
    "    print(\"Clustered\")\n",
    "    return df"
   ],
   "id": "86a82675523549d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Izračunam cluster",
   "id": "f26f06ae30b43840"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = cluster_louvain(data, 'Embedding', 0.92)  # <- similarity_threshold\n",
    "data = data.drop(columns=['Embedding'])  # remove the vectors from data we don't need them anymore\n",
    "data[['Article ID', 'Datum', 'Medij', 'Cluster', 'Tekst']].head(100)"
   ],
   "id": "625c0c0a685a3c0d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
