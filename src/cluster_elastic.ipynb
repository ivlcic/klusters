{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "!pip install pandas numpy networkx numpy scikit-learn",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel(os.path.join('..', 'data', 'Reworkan data 4.xlsx'))\n",
    "data.head()"
   ],
   "id": "912cef934ed4f337",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "V realnem projektu, pazi na okoljske spremeljivke",
   "id": "20bd7ebd46eddccd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(os.getenv('CPTM_SPASS'))\n",
    "print(os.getenv('CPTM_SURL'))\n",
    "print(os.getenv('CPTM_SUSER'))"
   ],
   "id": "1a916cccf53077a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Funkcije za pridobivanje 탑e obstoje훾ih vektorjev iz elastike.",
   "id": "b4af254a9d72b6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy\n",
    "from esdl import Elastika\n",
    "\n",
    "def embed_elastic(df: pd.DataFrame, col_name: str = 'Tekst', target_col_name: str = 'Embedding') -> pd.DataFrame:\n",
    "    # Split the DataFrame into batches of 500 rows\n",
    "    batch_size = 1000\n",
    "    num_batches = (len(df) + batch_size - 1) // batch_size\n",
    "    es_column = 'vector_768___textonic_v2'\n",
    "    id_column = 'Article ID'\n",
    "    \n",
    "    responses = pd.DataFrame()\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = (i + 1) * batch_size\n",
    "        \n",
    "        batch = df[id_column].iloc[start_idx:end_idx].tolist()\n",
    "        \n",
    "        # Call the remote service for the current batch\n",
    "        requests = Elastika()\n",
    "        requests.limit(1000)\n",
    "        requests.field(['uuid', es_column])\n",
    "        requests.filter_uuid(batch)\n",
    "        \n",
    "        # Collect the responses\n",
    "        articles = requests.gets('1996-01-01', '2030-01-01')\n",
    "        result = {\n",
    "            id_column: [],\n",
    "            target_col_name: []\n",
    "        }\n",
    "        for a in articles:\n",
    "            if es_column not in a.data:\n",
    "                continue\n",
    "            vect = numpy.array(a.data[es_column])\n",
    "            result[id_column].append(a.uuid)\n",
    "            result[target_col_name].append(vect)\n",
    "        print(f'Requested/received/valid vector : {len(batch)}/{len(articles)}/{len(result[target_col_name])}')\n",
    "        # Convert the collected responses to a DataFrame\n",
    "        response_df = pd.DataFrame(result)\n",
    "        responses = pd.concat([responses, response_df])\n",
    "        \n",
    "    # Merge the responses back into the original DataFrame\n",
    "    orig_len = len(df)\n",
    "    df = pd.merge(df, responses, on=id_column, how='left').dropna(subset=[target_col_name])\n",
    "    print(f'Requested/Successful {orig_len}/{len(df)}')\n",
    "    return df"
   ],
   "id": "3bd2621f2d5b856a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Kli훾em vektorizacijo na stolpcu 'Text' in dobim stolpec z vektorjem 'Embedding'",
   "id": "6248742bae82169c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = embed_elastic(data, 'Tekst', 'Embedding')\n",
    "data[['Article ID', 'Datum', 'Medij', 'Tekst', 'Embedding']].head(100)"
   ],
   "id": "6bb737632c935461",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definiram funkcijo za cluster",
   "id": "be7c8b653ddc137b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cluster_louvain(df: pd.DataFrame, col_name: str = 'Embedding', similarity_threshold: float = 0.96):\n",
    "    print(\"Clustering ...\")\n",
    "    embeddings = np.array(df[col_name].to_list())\n",
    "    labels = [0] * len(embeddings)\n",
    "    x = cosine_similarity(embeddings, embeddings)\n",
    "    similarity_matrix = x > similarity_threshold\n",
    "    graph = nx.from_numpy_array(similarity_matrix)\n",
    "    communities = nx.algorithms.community.louvain_communities(graph, resolution=0.1)\n",
    "    for community in communities:\n",
    "        initial_member = min(community)\n",
    "        for member in community:\n",
    "            labels[member] = initial_member\n",
    "\n",
    "    df['Cluster'] = pd.Series(labels)\n",
    "    print(\"Clustered\")\n",
    "    return df"
   ],
   "id": "86a82675523549d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Izra훾unam cluster",
   "id": "f26f06ae30b43840"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = cluster_louvain(data, 'Embedding', 0.92)  # <- similarity_threshold\n",
    "data = data.drop(columns=['Embedding'])  # remove the vectors from data we don't need them anymore\n",
    "data[['Article ID', 'Datum', 'Medij', 'Cluster', 'Tekst']].head(100)"
   ],
   "id": "625c0c0a685a3c0d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
